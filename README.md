# GATES
## Graph Attention Networks for Entity Summarization

The  entity  summarization  task  has  recently  gained  signifi-cant  attention  to  provide  concise  information  about  various  facts  con-tained  in  large  knowledge  graphs.  Presently,  the  best  performing  ap-proaches rely on a supervised learning model using neural network meth-ods with sequence to sequence learning. In contrast with existing meth-ods, we introduce GATES as a new approach for entity summarizationtask using deep learning for graphs. It combines leveraging graph struc-ture and textual semantics to encode triples and advantages deep learn-ing on graphs to generate a score for each candidate triple. We evalu-ated GATES on the ESBM benchmark, which comprises DBpedia andLinkedMDB datasets. Our results show that GATES outperforms state-of-the-art approaches on all datasets, in which F1 scores for the top-5 andtop-10 of DBpedia are 0.462 and 0,615, respectively. Also, F1 scores forthe top-5 and top-10 of LinkedMDB are 0.495 and 0.514, consecutively.

## Dataset

On this experiment, ESBM benchmark v.1.2 is used to train and test GATES

